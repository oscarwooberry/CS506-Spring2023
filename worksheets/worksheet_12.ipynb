{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Worksheet 12\n",
    "\n",
    "Name: Yicun Wu\n",
    "UID: U60263210\n",
    "\n",
    "### Topics\n",
    "\n",
    "- Naive Bayes\n",
    "- Model Evaluation\n",
    "\n",
    "### Naive Bayes\n",
    "\n",
    "| Attribute A | Attribute B | Attribute C | Class |\n",
    "|-------------|-------------|-------------|-------|\n",
    "| Yes         | Single      | High        | No    |\n",
    "| No          | Married     | Mid         | No    |\n",
    "| No          | Single      | Low         | No    |\n",
    "| Yes         | Married     | High        | No    |\n",
    "| No          | Divorced    | Mid         | Yes   |\n",
    "| No          | Married     | Low         | No    |\n",
    "| Yes         | Divorced    | High        | No    |\n",
    "| No          | Single      | Mid         | Yes   |\n",
    "| No          | Married     | Low         | No    |\n",
    "| No          | Single      | Mid         | Yes   |\n",
    "\n",
    "a) Compute the following probabilities:\n",
    "\n",
    "- P(Attribute A = Yes | Class = No)\n",
    "- P(Attribute B = Divorced | Class = Yes)\n",
    "- P(Attribute C = High | Class = No)\n",
    "- P(Attribute C = Mid | Class = Yes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P(Attribute A = Yes | Class = No) = 3/7<br>\n",
    "P(Attribute B = Divorced | Class = Yes) = 1/3<br>\n",
    "P(Attribute C = High | Class = No) = 3/7<br>\n",
    "P(Attribute C = Mid | Class = Yes) = 3/3<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Classify the following unseen records:\n",
    "\n",
    "- (Yes, Married, Mid)\n",
    "- (No, Divorced, High)\n",
    "- (No, Single, High)\n",
    "- (No, Divorced, Low)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P(C=Y) = 3/10\n",
    "P(C=N) = 7/10\n",
    "\n",
    "(Yes, Married, Mid) = P(C=Y) * P(Yes | C = Yes) * P(Married | C = Yes) * P(Mid | C = Yes) **-vs-** P(C=N) * P(Yes | C = No) * P(Married | C = No) * P(Mid | C = No) = 0 vs 7/10 * 3/7 * 4/7 * 1/7 = **No**\n",
    "\n",
    "(No, Divorced, High) = P(C=Y) * P(No|C=Y) * P(Divorced|C=Y) * P(High|C=Y) **-vs-** P(C=N) * P(No|C=N) * P(Divorced|C=N) * P(High|C=N) = 3/10 * 3/3 * 1/3 * 0 **-vs-** 7/10 * 4/7 * 1/7 * 3/7 = **No**\n",
    "\n",
    "(No, Single, High) = P(C=Y) * P(No|C=Y) * P(Single|C=Y) * P(High|C=Y) **-vs-** P(C=N) * P(No|C=N) * P(Single|C=N) * P(High|C=N) = 3/10 * 3/3 * 2/3 * 0 **-vs-** 7/10 * 4/7 * 2/7 * 3/7 = **No**\n",
    "\n",
    "(No, Divorced, Low) = P(C=Y) * P(No|C=Y) * P(Divorced|C=Y) * P(Low|C=Y) **-vs-** P(C=N) * P(No|C=N) * P(Divorced|C=N) * P(Low|C=N) = 3/10 * 3/3 * 1/3 * 0 **-vs-** 7/10 * 4/7 * 1/7 * 3/7 = **No**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation\n",
    "\n",
    "a) Write a function to generate the confusion matrix for a list of actual classes and a list of predicted classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4. 3.]\n",
      " [1. 2.]]\n"
     ]
    }
   ],
   "source": [
    "actual_class = [\"Yes\", \"No\", \"No\", \"Yes\", \"No\", \"No\", \"Yes\", \"No\", \"No\", \"No\"]\n",
    "predicted_class = [\"Yes\", \"No\", \"Yes\", \"No\", \"No\", \"No\", \"Yes\", \"Yes\", \"Yes\", \"No\"]\n",
    "import numpy as np\n",
    "def confusion_matrix(actual, predicted):\n",
    "    unique_labels = np.unique(actual)\n",
    "    num_labels = len(unique_labels)\n",
    "    confusion_mat = np.zeros((num_labels, num_labels))\n",
    "    \n",
    "    for i in range(len(actual)):\n",
    "        true_label = actual[i]\n",
    "        pred_label = predicted[i]\n",
    "        true_idx = np.where(unique_labels == true_label)[0][0]\n",
    "        pred_idx = np.where(unique_labels == pred_label)[0][0]\n",
    "        confusion_mat[true_idx, pred_idx] += 1\n",
    "    \n",
    "    return confusion_mat\n",
    "\n",
    "print(confusion_matrix(actual_class, predicted_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Assume you have the following Cost Matrix:\n",
    "\n",
    "|            | predicted = Y | predicted = N |\n",
    "|------------|---------------|---------------|\n",
    "| actual = Y |       -1      |       5       |\n",
    "| actual = N |        10     |       0       |\n",
    "\n",
    "What is the cost of the above classification?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n"
     ]
    }
   ],
   "source": [
    "def calculate_cost(cost_matrix, confusion_matrix):\n",
    "    cost = np.sum(np.multiply(cost_matrix, confusion_matrix))\n",
    "    return cost\n",
    "\n",
    "confusion = [[4, 3], [1, 2]]\n",
    "cost_mat = [[-1, 5], [10, 0]]\n",
    "\n",
    "print(calculate_cost(cost_mat, confusion))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cost is 21"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Write a function that takes in the actual values, the predictions, and a cost matrix and outputs a cost. Test it on the above example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21.0\n"
     ]
    }
   ],
   "source": [
    "def find_cost(actual, predictions, cost):\n",
    "    confusion_mat = confusion_matrix(actual, predictions)\n",
    "    return calculate_cost(cost, confusion_mat)\n",
    "\n",
    "print(find_cost(actual_class, predicted_class, cost_mat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) What is the difference between a testing set and a validation set?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation set- used for hyperparameter tuning<br>\n",
    "\n",
    "Test set- used for final model accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e) What are some things you can do to handle the case where you have a highly imbalanced dataset (i.e. there are way more of one class than another). Describe both how you can provide better visibility into the failures of the model and how you can set your model training up for success."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use data augmentation, and ensembling methods. By training different models on different subsets of the data, we'll be able to prevent overfitting and improve the generalization of the model on unseen data. Ensembling helps reduce bias towards the majority class. data augmentation can use fewer examples of the majority classes, and more of the underrepresented one, to achieve a better balance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
